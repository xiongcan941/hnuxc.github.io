# linux内核共享内存
- 调用shmget()创建共享内存
- 调用shmat()映射共享内存至进程虚拟空间
- 调用shmdt()解除映射关系

## 统一封装的接口
信号量、消息队列、共享内存有着统一的封装和管理机制，为此我们提供了对应的namespace和ipc_ids结构体。ipc_ids[0]用于信号量，ipc_ids[1]用于消息队列，ipc_ids[2]用于共享内存，分别可以通过sem_ids、msg_ids、shm_ids来访问。ipc_ids中in_use表示当前有多少个ipc,seq和next_id用于一起生成ipc唯一的id，ipcs_idr是一棵基数树，一旦涉及从一个整数查找一个对象它都是最好的选择。

```
struct ipc_namespace {
	struct ipc_ids	ids[3];
	---
}

#define IPC_SEM_IDS 0
#define IPC_MSG_IDS 1
#define IPC_SHM_IDS 2

#define sem_ids(ns) ((ns)->ids[IPC_SEM_IDS])
#define msg_ids(ns) ((ns)->ids[IPC_MSG_IDS])
#define shm_ids(ns) ((ns)->ids[IPC_SHM_IDS])

struct ipc_ids {
    int in_use;
    unsigned short seq;
    struct rw_semaphore rwsem;
    struct idr ipcs_idr;
    int max_idx;
    struct rhashtable key_ht;
};

struct idr {
    struct radix_tree_root	idr_rt;
    unsigned int		idr_base;
    unsigned int		idr_next;
};

```
信号量、消息队列、共享内存都通过基数树来管理各自的对象，三种ipc对应的结构体中第一项均为struct kern_ipc_perm，该结构体对应的id会存储在基数树之中，可以通过ipc_obtain_object_idr()获取。

```
struct shmid_kernel /* private to the kernel */
{  
    struct kern_ipc_perm  shm_perm;
......
} __randomize_layout;

struct kern_ipc_perm *ipc_obtain_object_idr(struct ipc_ids *ids, int id)
{
    struct kern_ipc_perm *out;
    int lid = ipcid_to_idx(id);
    out = idr_find(&ids->ipcs_idr, lid);
    return out;
}
```

共享内存会对ipc_obtain_object_idr()进行封装
```
static inline struct shmid_kernel *shm_obtain_object(struct ipc_namespace *ns, int id)
{
    struct kern_ipc_perm *ipcp = ipc_obtain_object_idr(&shm_ids(ns), id);
    return container_of(ipcp, struct shmid_kernel, shm_perm);
}
```
由此，我们实现了对这三种进程间通信方式统一的封装抽象。首先用名字空间存储三种ipc，然后对应的ipc_ids会描述该通信方式的特点，并包含一个基数树存储id从而找到其实际运行的多个通信的结构体。

我们将id传递给用户，用户就可以通过id获取到对应的kern_ipc_perm从而获取到shmid_kernel了，从而获取到对应的shm_file，再将其映射到用户空间（实际上就是在用户进程的mm_struct里创建一个vma,其中vma_file指向该文件）

## shmget()创建共享内存——创建对应的shmid_kernel及各相关结构体
该函数创建对应的ipc_namespace指针并指向当进程的ipc_ns（current->nsproxy->ipc_ns），初始化共享内存对应的操作shm_ops，并将传入参数key,size,shmflg封装为传参shm_params，最终调用ipcget()。
```
SYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)
{
    struct ipc_namespace *ns;
    static const struct ipc_ops shm_ops = {
        .getnew = newseg,
        .associate = shm_security,
        .more_checks = shm_more_checks,
    };
    struct ipc_params shm_params;
    ns = current->nsproxy->ipc_ns;
    shm_params.key = key;
    shm_params.flg = shmflg;
    shm_params.u.size = size;
    return ipcget(ns, &shm_ids(ns), &shm_ops, &shm_params);
}
```
ipcget()会根据传参key的类型是否是IPC_PRIVATE选择调用ipcget_new()创建或者调用ipcget_public()打开对应的共享内存
```
int ipcget(struct ipc_namespace *ns, struct ipc_ids *ids,
            const struct ipc_ops *ops, struct ipc_params *params)
{
    if (params->key == IPC_PRIVATE)
        return ipcget_new(ns, ids, ops, params);
    else
        return ipcget_public(ns, ids, ops, params);
}
```
ipcget_new()会根据定义的ops->getnew()创建新的ipc对象，即上面定义的newseg()。ipcget_public()会按照key查找struct kern_ipc_perm。如果没有找到，那就看是否设置了IPC_CREAT,如果设置了，就调用ops->getnew()创建一个新的，否则返回错误ENOENT。如果找到了，就将对应的id返回。
```
static int ipcget_new(struct ipc_namespace *ns, struct ipc_ids *ids,
        const struct ipc_ops *ops, struct ipc_params *params)
{
    int err;
    down_write(&ids->rwsem);
    err = ops->getnew(ns, params);
    up_write(&ids->rwsem);
    return err;
}

static int ipcget_public(struct ipc_namespace *ns, struct ipc_ids *ids,
        const struct ipc_ops *ops, struct ipc_params *params)
{
    struct kern_ipc_perm *ipcp;
    int flg = params->flg;
    int err;
    /*
     * Take the lock as a writer since we are potentially going to add
     * a new entry + read locks are not "upgradable"
     */
    down_write(&ids->rwsem);
    ipcp = ipc_findkey(ids, params->key);
    if (ipcp == NULL) {
        /* key not used */
        if (!(flg & IPC_CREAT))
            err = -ENOENT;
        else
            err = ops->getnew(ns, params);
    } else {
......
            if (!err)
                /*
                 * ipc_check_perms returns the IPC id on
                 * success
                 */
                err = ipc_check_perms(ns, ipcp, ops, params);
        }
        ipc_unlock(ipcp);
    }
    up_write(&ids->rwsem);
    return err;
}
```

所以新的创建最后都会走到注册的newseg()函数。该函数主要逻辑为：

- 通过kvmalloc()在直接映射区分配一个struct shmid_kernel结构体，该结构体用于描述共享内存。
- 调用hugetlb_file_setup()或shmem_kernel_file_setup()关联文件。如何实现物理内存向多个进程的虚拟内存映射呢？这里就要靠文件来实现：虚拟地址空间可以映射到一个文件，文件是可以跨进程共享的。这里我们并不设映射到硬盘上存储的文件，而是映射到内存文件系统上的文件。
- 通过ipc_addid()将新创建的struct shmid_kernel结构挂到shm_ids里面的基数树上，返回相应的id,并且将struct shmid_kernel挂到当前进程的sysvshm的shm_clist的list_head中
```
/**
 * newseg - Create a new shared memory segment
 * @ns: namespace
 * @params: ptr to the structure that contains key, size and shmflg
 *
 * Called with shm_ids.rwsem held as a writer.
 */
static int newseg(struct ipc_namespace *ns, struct ipc_params *params)
{
    key_t key = params->key;
    int shmflg = params->flg;
    size_t size = params->u.size;
    int error;
    struct shmid_kernel *shp;
    size_t numpages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;
    struct file *file;
    char name[13];
......
    shp = kvmalloc(sizeof(*shp), GFP_KERNEL);
......
    shp->shm_perm.key = key;
    shp->shm_perm.mode = (shmflg & S_IRWXUGO);
    shp->mlock_user = NULL;
    shp->shm_perm.security = NULL;
......
    if (shmflg & SHM_HUGETLB) {
......
        file = hugetlb_file_setup(name, hugesize, acctflag,
                  &shp->mlock_user, HUGETLB_SHMFS_INODE,
                (shmflg >> SHM_HUGE_SHIFT) & SHM_HUGE_MASK);
    } else {
......
        file = shmem_kernel_file_setup(name, size, acctflag);
    }
......
    shp->shm_cprid = get_pid(task_tgid(current));
    shp->shm_lprid = NULL;
    shp->shm_atim = shp->shm_dtim = 0;
    shp->shm_ctim = ktime_get_real_seconds();
    shp->shm_segsz = size;
    shp->shm_nattch = 0;
    shp->shm_file = file;
    shp->shm_creator = current;
    /* ipc_addid() locks shp upon success. */
    error = ipc_addid(&shm_ids(ns), &shp->shm_perm, ns->shm_ctlmni);
......
    list_add(&shp->shm_clist, &current->sysvshm.shm_clist);
    /*
     * shmid gets reported as "inode#" in /proc/pid/maps.
     * proc-ps tools use this. Changing this will break them.
     */
    file_inode(file)->i_ino = shp->shm_perm.id;
    ns->shm_tot += numpages;
    error = shp->shm_perm.id;
......
}
```
实际上shmem_kernel_file_setup()会在shmem文件系统里面创建一个文件：__shmem_file_setup()会创建新的shmem文件对应的dentry和inode，并将它们两个关联起来，然后分配一个struct file结构来表示新的shmem文件，并且指向独特的shmem_file_operations。
```
/**
 * shmem_kernel_file_setup - get an unlinked file living in tmpfs which must be kernel internal.  
 * @name: name for dentry (to be seen in /proc/<pid>/maps
 * @size: size to be set for the file
 * @flags: VM_NORESERVE suppresses pre-accounting of the entire object size */
struct file *shmem_kernel_file_setup(const char *name, loff_t size, unsigned long flags)
{
    return __shmem_file_setup(name, size, flags, S_PRIVATE);
}

static struct file *__shmem_file_setup(const char *name, loff_t size,
               unsigned long flags, unsigned int i_flags)
{
    struct file *res;
    struct inode *inode;
    struct path path;
    struct super_block *sb;
    struct qstr this;
......
    this.name = name;
    this.len = strlen(name);
    this.hash = 0; /* will go */
    sb = shm_mnt->mnt_sb;
    path.mnt = mntget(shm_mnt);
    path.dentry = d_alloc_pseudo(sb, &this);
    d_set_d_op(path.dentry, &anon_ops);
......
    inode = shmem_get_inode(sb, NULL, S_IFREG | S_IRWXUGO, 0, flags);
    inode->i_flags |= i_flags;
    d_instantiate(path.dentry, inode);
    inode->i_size = size;
......
    res = alloc_file(&path, FMODE_WRITE | FMODE_READ,
        &shmem_file_operations);
    return res;
}
```