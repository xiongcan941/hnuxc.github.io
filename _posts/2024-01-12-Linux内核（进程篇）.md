---
layout:     post
title:      Linux内核（进程篇）
subtitle:   Linux内核（进程篇）
date:       2024-01-12
author:     xc
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 进程
    - linux内核
---

# 一、进程创建

    Linux系统进程创建实质上是对父进程的拷贝，对于父进程资源的拷贝会导致进程创建效率下降，Linux采用三种机制解决此问题：

1、写时复制（Copy On Write,COW），子进程创建时与父进程共享页框，即共享cr2寄存器，但是将其中页表项权限设置为只读，父进程或者子进程任一一方试图改写物理页，就会产生缺页异常（Page Fault），这是内核会把这个页复制到一个新的页框中并标记为可写。原来的页面仍然是写保护的，如果有进程再次访问该页框，内核会检测该进程是否为该页框的唯一属主，如果是则将页框标记为可写。判断页框是否唯一是由页描述符（struct page）_count（最新版本是_refcount）引用计数原子操作实现的。

2、轻量级进程允许父子进程共享每进程在内核的很多数据结构，如页表、打开的文件及信号处理。

3、vfork()系统调用创建的子进程时，会阻塞父进程，直到子进程退出或者execve一个新进程父进程才恢复，这样就保证了父进程不会访问共享空间。

## 1、clone()、fork()和vfork()

Linux提供了三个创建进程的系统调用clone()、fork()和vfork()。
1、fork：创建子进程，复制父进程的全部资源。
2、vfork：创建子进程，共享父进程的资源。会将父进程阻塞，保证子进程先于父进程执行，直到子进程退出或执行新程序。
3、clone：可以通过clone标志创建子进程，不同标志可以实现不同的效果，复制不同的资源，具体标志含义见下方clone_flag说明。

Linux5.6.4版本clone()、fork()和vfork()系统调用：

    Linux5.6.4的clone()、fork()和vfork()都是通过_do_fork(&args)实现，Linux3.0内核使用的是do_fork()实现。由于do_fork()存在struct pt_regs入参，所以Linux3.0内核的clone()、fork()和vfork()系统调用是和体系结构相关的。do_fork()和_do_fork()在创建进程时没有太大区别，核心都是copy_process()，只是在TLS（线程局部存储段）复制过程中有差别。前者是通过struct pt_regs传入tls，后者通过一个unsigned long型传递。而且TLS只有在clone_flags设置CLONE_SETTLS标志才会复制。
fork()只使用了SIGCHLD标志，，子进程终止后会发送SIGCHLD信号通知父进程。
vfork()传递CLONE_VFORK和CLONE_VM标志，do_fork函数中依据这个标志把父进程加入等待队列，直到子进程释放自己的内存地址空间（也就是说，子进程结束或执行新的程序），CLONE_VM表示子进程与父进程共享内存空间。
clone()传递的参数来自用户空间，通常用于创建线程。pthread_create即调用clone实现。

## 2、clone_flag

```
/*
 * cloning flags:
 */
#define CSIGNAL        0x000000ff    /* signal mask to be sent at exit */
/* 共享内存描述符和所有页表 */
#define CLONE_VM    0x00000100    /* set if VM shared between processes */
/* 共享根目录和当前目录 */
#define CLONE_FS    0x00000200/* set if fs info shared between processes */
/* 共享打开文件表 */
#define CLONE_FILES    0x00000400    /* set if open files shared between processes */
/* 共享信号处理程序表、阻塞信号表和挂起信号表，必须和CLONE_VM同时使用 */
#define CLONE_SIGHAND    0x00000800    /* set if signal handlers and blocked signals shared */

#define CLONE_PIDFD    0x00001000    /* set if a pidfd should be placed in parent */
/* 如果父进程被跟踪，那么子进程也被跟踪 */
#define CLONE_PTRACE    0x00002000    /* set if we want to let tracing continue on the child too */
/* vfork()系统调用 */
#define CLONE_VFORK    0x00004000    /* set if the parent wants the child to wake it up on mm_release */
/* 创建出的进程是兄弟关系，不是父子关系，init进程或容器init进程不可以使用该标志，init进程是所有用户进程的祖先 */
#define CLONE_PARENT    0x00008000    /* set if we want to have the same parent as the cloner */
/* 父子进程在同一个线程组，Linux内核为每一个线程和进程创建一个pid，POSIX协议规定一个进程内部线程共享一个PID，因而Linux通过线程组满足POSIX协议 */
#define CLONE_THREAD    0x00010000    /* Same thread group? */
/* clone需要自己的命名空间时设置，不能与CLONE_FS同时设置 */
#define CLONE_NEWNS    0x00020000    /* New mount namespace group */
/* 共享system V SEM_UNDO操作 */
#define CLONE_SYSVSEM    0x00040000    /* share system V SEM_UNDO semantics */
/* 创建新的TLS */
#define CLONE_SETTLS    0x00080000    /* create a new TLS for the child */
/* 把子进程的PID写入由ptid参数所指向的父进程的用户态变量
即执行如下代码：
    if (clone_flags & CLONE_PARENT_SETTID)
        put_user(nr, args->parent_tid);
args->parent_tid为clone()系统调用入参parent_tid */
#define CLONE_PARENT_SETTID    0x00100000    /* set the TID in the parent */
#define CLONE_CHILD_CLEARTID    0x00200000    /* clear the TID in the child */
#define CLONE_DETACHED        0x00400000    /* Unused, ignored */
#define CLONE_UNTRACED        0x00800000    /* set if the tracing process can't force CLONE_PTRACE on this clone */
/* 把子进程的PID写入由ctid参数所指向的子进程的用户态变量
即执行如下代码：
p->set_child_tid = (clone_flags & CLONE_CHILD_SETTID) ? args->child_tid : NULL;
args->child_tid 为clone()系统调用入参child_tid，p为子进程task_struct */
#define CLONE_CHILD_SETTID    0x01000000    /* set the TID in the child */

/* 命名空间用于容器技术,在容器中，CPU和内存资源使通过Cgroup划分的，PID，IPC,
网络等资源使通过命名空间划分的。 */

#define CLONE_NEWCGROUP        0x02000000    /* New cgroup namespace */
/* 划分UTS（Universal Time sharing System）命名空间，分配新的UTS空间 */
#define CLONE_NEWUTS        0x04000000    /* New utsname namespace */
/*划分IPC（进程间通信）命名空间，信号量，共享内存，消息队列等进程间通信用到资源*/
#define CLONE_NEWIPC        0x08000000    /* New ipc namespace */
/*子进程创建新的User namespace，用于管理User ID和Group ID的映射，起到隔离User ID的作用。一个User namespace可以形成一个容器，容器里第一个进程uid为0*/
#define CLONE_NEWUSER        0x10000000    /* New user namespace */
/*划分PID命名空间，分配新的PID空间*/
#define CLONE_NEWPID        0x20000000    /* New pid namespace */
/*划分网络命名空间，分配网络接口*/
#define CLONE_NEWNET        0x40000000    /* New network namespace */
#define CLONE_IO        0x80000000    /* Clone io context */
```

## do_fork()实现

从clone()、fork()和vfork()系统调用可以看出，它们最终都调用_do_fork()（老版本是do_fork()）来处理。

```
struct kernel_clone_args {
    u64 flags;
    int __user *pidfd;
    int __user *child_tid;
    int __user *parent_tid;
    int exit_signal;
    unsigned long stack;
    unsigned long stack_size;
    unsigned long tls;
    pid_t *set_tid;
    /* Number of elements in *set_tid */
    size_t set_tid_size;
};
/*
 *  Ok, this is the main fork-routine.
 *
 * It copies the process, and if successful kick-starts
 * it and waits for it to finish using the VM if required.
 *
 * args->exit_signal is expected to be checked for sanity by the caller.
 */
long _do_fork(struct kernel_clone_args *args)
{
    u64 clone_flags = args->flags;
    struct completion vfork;
    struct pid *pid;
    struct task_struct *p;
    int trace = 0;
    long nr;

    /*
     * Determine whether and which event to report to ptracer.  When
     * called from kernel_thread or CLONE_UNTRACED is explicitly
     * requested, no event is reported; otherwise, report if the event
     * for the type of forking is enabled.
     */
    if (!(clone_flags & CLONE_UNTRACED)) {
        if (clone_flags & CLONE_VFORK)
            trace = PTRACE_EVENT_VFORK;
        else if (args->exit_signal != SIGCHLD)
            trace = PTRACE_EVENT_CLONE;
        else
            trace = PTRACE_EVENT_FORK;

        if (likely(!ptrace_event_enabled(current, trace)))
            trace = 0;
    }

    /* copy_process创建子进程描述符 */
    p = copy_process(NULL, trace, NUMA_NO_NODE, args);
    add_latent_entropy();

    if (IS_ERR(p))
        return PTR_ERR(p);

    /*
     * Do this prior waking up the new thread - the thread pointer
     * might get invalid after that point, if the thread exits quickly.
     */
    trace_sched_process_fork(current, p);

    /* 分配进程PID */
    pid = get_task_pid(p, PIDTYPE_PID);
    nr = pid_vnr(pid);

    if (clone_flags & CLONE_PARENT_SETTID)
        put_user(nr, args->parent_tid);

    if (clone_flags & CLONE_VFORK) {
        p->vfork_done = &vfork;
        init_completion(&vfork);
        get_task_struct(p);
    }

    /* 唤醒子进程，并加入运行队列 */
    wake_up_new_task(p);

    /* forking complete and child started to run, tell ptracer */
    if (unlikely(trace))
        ptrace_event_pid(trace, pid);

    /* 如果设置CLONE_VFORK标志，则将父进程加入等待队列，直到子进程释放自己的内存地址空间 */
    if (clone_flags & CLONE_VFORK) {
        if (!wait_for_vfork_done(p, &vfork))
            ptrace_event_pid(PTRACE_EVENT_VFORK_DONE, pid);
    }

    put_pid(pid);
    return nr;
}
```

_do_fork()调用copy_process()复制进程描述符，这是创建进程的关键步骤。
调用wake_up_new_task将唤醒子进程，并加入调度队列。
如果设置了CLONE_VFORK，则把父进程加入等待队列，直到子进程释放自己的内存地址空间（也就是说，子进程结束或执行新的程序），这里反映了vfork()可以保证子进程先于父进程执行的特点。

## 4、copy_process()实现

copy_process()创建子进程的进程描述符以及进程执行需要的其他数据结构。Linux5.6.4内核copy_process实现如下：
1、copy_process首先对clone_flags做参数检查，对于不能同时使用或者必须同时使用的CLONE_XXX做限制；例如clone_signal设置了，但是clone_vm未设置等；
2、调用dup_task_struct获取进程描述符c，并初始化thread_info，thread_info与内核栈共分配两页，并且将thread_info->task设置为c，c->thread_info为刚刚初始化的thread_info；
3、初始化进程描述符的链表，信号及时间等内容；
4、初始化子进程调度策略，优先级，调度类等进程调度相关成员；
5、子进程复制父进程信息，文件，信号，内存等内容，copy_xxx()类函数调用；
6、调用copy_thread_tls()，初始化体系结构相关的thread_struct，X86架构下，将eax置为0，esp置为子进程内核栈基地址，eip置为ret_from_fork。所以子进程返回值为0，子进程从ret_from_fork开始执行；ret_from_fork即完成中断的收尾工作，恢复原先运行的“用户”程序状态，弹出内核栈上所保存的各寄存器值。

内核中栈的管理情况如上，stack->pt_regs指向保存的用户态栈信息（task_pt_regs获取）。thread保存的是内核栈的信息。
task_struct数据结构中的stack成员指向thread_union结构（Linux内核通过thread_union联合体来表示进程的内核栈）

```
union thread_union {
    struct thread_info thread_info;
    unsigned long stack[THREAD_SIZE/sizeof(long)];  
};
```

```
struct thread_struct {
    /* Cached TLS descriptors: */
    struct desc_struct    tls_array[GDT_ENTRY_TLS_ENTRIES];
#ifdef CONFIG_X86_32
    unsigned long        sp0;sp0指向了用户态栈
sp指向内核态栈
#endif
    unsigned long        sp;
#ifdef CONFIG_X86_32
    unsigned long        sysenter_cs;
#else
    unsigned short        es;
    unsigned short        ds;
    unsigned short        fsindex;
    unsigned short        gsindex;
#endif

#ifdef CONFIG_X86_64
    unsigned long        fsbase;
    unsigned long        gsbase;
#else
    /*
     * XXX: this could presumably be unsigned short.  Alternatively,
     * 32-bit kernels could be taught to use fsindex instead.
     */
    unsigned long fs;
    unsigned long gs;
#endif

    /* Save middle states of ptrace breakpoints */
    struct perf_event    *ptrace_bps[HBP_NUM];
    /* Debug status used for traps, single steps, etc... */
    unsigned long           debugreg6;
    /* Keep track of the exact dr7 value set by the user */
    unsigned long           ptrace_dr7;
    /* Fault info: */
    unsigned long        cr2;
    unsigned long        trap_nr;
    unsigned long        error_code;
#ifdef CONFIG_VM86
    /* Virtual 86 mode info */
    struct vm86        *vm86;
#endif
    /* IO permissions: */
    struct io_bitmap    *io_bitmap;

    /*
     * IOPL. Priviledge level dependent I/O permission which is
     * emulated via the I/O bitmap to prevent user space from disabling
     * interrupts.
     */
    unsigned long        iopl_emul;

    mm_segment_t        addr_limit;

    unsigned int        sig_on_uaccess_err:1;
    unsigned int        uaccess_err:1;    /* uaccess failed */

    /* Floating point and extended processor state */
    struct fpu        fpu;
    /*
     * WARNING: 'fpu' is dynamically-sized.  It *MUST* be at
     * the end.
     */
};
```

7、设置进程与父进程之间的关系；
8、total_forks加1；
9、返回子进程进程描述符。

```
/*
 * This creates a new process as a copy of the old one,
 * but does not actually start it yet.
 *
 * It copies the registers, and all the appropriate
 * parts of the process environment (as per the clone
 * flags). The actual kick-off is left to the caller.
 */
static __latent_entropy struct task_struct *copy_process(
                    struct pid *pid,
                    int trace,
                    int node,
                    struct kernel_clone_args *args)
{
    int pidfd = -1, retval;
    struct task_struct *p;
    struct multiprocess_signals delayed;
    struct file *pidfile = NULL;
    u64 clone_flags = args->flags;
    struct nsproxy *nsp = current->nsproxy;

    /*
     * Don't allow sharing the root directory with processes in a different
     * namespace
     */
     /* 错误标志检查：CLONE_NEWNS和CLONE_FS不能同时设置 */
    if ((clone_flags & (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))
        return ERR_PTR(-EINVAL);

    /* 错误标志检查：CLONE_NEWUSER和CLONE_FS不能同时设置 */
    if ((clone_flags & (CLONE_NEWUSER|CLONE_FS)) == (CLONE_NEWUSER|CLONE_FS))
        return ERR_PTR(-EINVAL);

    /*
     * Thread groups must share signals as well, and detached threads
     * can only be started up within the thread group.
     */
     /* 错误标志检查：CLONE_THREAD设置时，CLONE_SIGHAND没有设置
         CLONE_THREAD设置后，子进程插入父进程同一线程组，共享父进程信号描述符*/
    if ((clone_flags & CLONE_THREAD) && !(clone_flags & CLONE_SIGHAND))
        return ERR_PTR(-EINVAL);

    /*
     * Shared signal handlers imply shared VM. By way of the above,
     * thread groups also imply shared VM. Blocking this case allows
     * for various simplifications in other code.
     */
     /* 错误标志检查：CLONE_SIGHAND设置，CLONE_VM没有设置
        共享信号处理的子进程必须共享内存描述符 */
    if ((clone_flags & CLONE_SIGHAND) && !(clone_flags & CLONE_VM))
        return ERR_PTR(-EINVAL);

    /*
     * Siblings of global init remain as zombies on exit since they are
     * not reaped by their parent (swapper). To solve this and to avoid
     * multi-rooted process trees, prevent global and container-inits
     * from creating siblings.
     */
     /* init进程single的flag会设置SIGNAL_UNKILLABLE标志，即init进程或者容器init进程不可以创建兄弟进程，因为这样会导致兄弟进程退出时变成僵死进程 */
    if ((clone_flags & CLONE_PARENT) &&
                current->signal->flags & SIGNAL_UNKILLABLE)
        return ERR_PTR(-EINVAL);

    /*
     * If the new process will be in a different pid or user namespace
     * do not allow it to share a thread group with the forking task.
     */
    if (clone_flags & CLONE_THREAD) {
        if ((clone_flags & (CLONE_NEWUSER | CLONE_NEWPID)) ||
            (task_active_pid_ns(current) != nsp->pid_ns_for_children))
            return ERR_PTR(-EINVAL);
    }

    /*
     * If the new process will be in a different time namespace
     * do not allow it to share VM or a thread group with the forking task.
     */
    if (clone_flags & (CLONE_THREAD | CLONE_VM)) {
        if (nsp->time_ns != nsp->time_ns_for_children)
            return ERR_PTR(-EINVAL);
    }

    if (clone_flags & CLONE_PIDFD) {
        /*
         * - CLONE_DETACHED is blocked so that we can potentially
         *   reuse it later for CLONE_PIDFD.
         * - CLONE_THREAD is blocked until someone really needs it.
         */
        if (clone_flags & (CLONE_DETACHED | CLONE_THREAD))
            return ERR_PTR(-EINVAL);
    }

    /*
     * Force any signals received before this point to be delivered
     * before the fork happens.  Collect up signals sent to multiple
     * processes that happen during the fork and delay them so that
     * they appear to happen after the fork.
     */
    sigemptyset(&delayed.signal);
    INIT_HLIST_NODE(&delayed.node);

    spin_lock_irq(&current->sighand->siglock);
    if (!(clone_flags & CLONE_THREAD))
        hlist_add_head(&delayed.node, &current->signal->multiprocess);
    recalc_sigpending();
    spin_unlock_irq(&current->sighand->siglock);
    retval = -ERESTARTNOINTR;
    if (signal_pending(current))
        goto fork_out;

    /* 为子进程获取进程描述符 */
    retval = -ENOMEM;
    p = dup_task_struct(current, node);
    if (!p)
        goto fork_out;

    /*
     * This _must_ happen before we call free_task(), i.e. before we jump
     * to any of the bad_fork_* labels. This is to avoid freeing
     * p->set_child_tid which is (ab)used as a kthread's data pointer for
     * kernel threads (PF_KTHREAD).
     */
     /* 把子进程的PID写入由ctid参数所指向的子进程的用户态变量 */
    p->set_child_tid = (clone_flags & CLONE_CHILD_SETTID) ? args->child_tid : NULL;
    /*
     * Clear TID on mm_release()?
     */
    p->clear_child_tid = (clone_flags & CLONE_CHILD_CLEARTID) ? args->child_tid : NULL;

    ftrace_graph_init_task(p);

    rt_mutex_init_task(p);

#ifdef CONFIG_PROVE_LOCKING
    DEBUG_LOCKS_WARN_ON(!p->hardirqs_enabled);
    DEBUG_LOCKS_WARN_ON(!p->softirqs_enabled);
#endif
    retval = -EAGAIN;
    if (atomic_read(&p->real_cred->user->processes) >=
            task_rlimit(p, RLIMIT_NPROC)) {
        if (p->real_cred->user != INIT_USER &&
            !capable(CAP_SYS_RESOURCE) && !capable(CAP_SYS_ADMIN))
            goto bad_fork_free;
    }
    current->flags &= ~PF_NPROC_EXCEEDED;

    retval = copy_creds(p, clone_flags);
    if (retval < 0)
        goto bad_fork_free;

    /*
     * If multiple threads are within copy_process(), then this check
     * triggers too late. This doesn't hurt, the check is only there
     * to stop root fork bombs.
     */
    retval = -EAGAIN;
    if (nr_threads >= max_threads)
        goto bad_fork_cleanup_count;

    delayacct_tsk_init(p);    /* Must remain after dup_task_struct() */
    p->flags &= ~(PF_SUPERPRIV | PF_WQ_WORKER | PF_IDLE);
    p->flags |= PF_FORKNOEXEC;
    INIT_LIST_HEAD(&p->children);  /* 初始化子进程链表 */
    INIT_LIST_HEAD(&p->sibling);  /* 初始化兄弟进程链表 */
    rcu_copy_process(p);
    p->vfork_done = NULL;
    spin_lock_init(&p->alloc_lock);  /* 初始化自旋锁 */

    init_sigpending(&p->pending); /* 初始化挂起信号 */

    /* 初始化时间 */
    p->utime = p->stime = p->gtime = 0;
#ifdef CONFIG_ARCH_HAS_SCALED_CPUTIME
    p->utimescaled = p->stimescaled = 0;
#endif
    prev_cputime_init(&p->prev_cputime);

#ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN
    seqcount_init(&p->vtime.seqcount);
    p->vtime.starttime = 0;
    p->vtime.state = VTIME_INACTIVE;
#endif

#if defined(SPLIT_RSS_COUNTING)
    memset(&p->rss_stat, 0, sizeof(p->rss_stat));
#endif

    p->default_timer_slack_ns = current->timer_slack_ns;

#ifdef CONFIG_PSI
    p->psi_flags = 0;
#endif

    task_io_accounting_init(&p->ioac);
    acct_clear_integrals(p);

    posix_cputimers_init(&p->posix_cputimers);

    p->io_context = NULL;
    audit_set_context(p, NULL);
    cgroup_fork(p);
#ifdef CONFIG_NUMA
    p->mempolicy = mpol_dup(p->mempolicy);
    if (IS_ERR(p->mempolicy)) {
        retval = PTR_ERR(p->mempolicy);
        p->mempolicy = NULL;
        goto bad_fork_cleanup_threadgroup_lock;
    }
#endif
#ifdef CONFIG_CPUSETS
    p->cpuset_mem_spread_rotor = NUMA_NO_NODE;
    p->cpuset_slab_spread_rotor = NUMA_NO_NODE;
    seqcount_init(&p->mems_allowed_seq);
#endif
#ifdef CONFIG_TRACE_IRQFLAGS
    p->irq_events = 0;
    p->hardirqs_enabled = 0;
    p->hardirq_enable_ip = 0;
    p->hardirq_enable_event = 0;
    p->hardirq_disable_ip = _THIS_IP_;
    p->hardirq_disable_event = 0;
    p->softirqs_enabled = 1;
    p->softirq_enable_ip = _THIS_IP_;
    p->softirq_enable_event = 0;
    p->softirq_disable_ip = 0;
    p->softirq_disable_event = 0;
    p->hardirq_context = 0;
    p->softirq_context = 0;
#endif

    p->pagefault_disabled = 0;

#ifdef CONFIG_LOCKDEP
    lockdep_init_task(p);
#endif

#ifdef CONFIG_DEBUG_MUTEXES
    p->blocked_on = NULL; /* not blocked yet */
#endif
#ifdef CONFIG_BCACHE
    p->sequential_io    = 0;
    p->sequential_io_avg    = 0;
#endif

    /* Perform scheduler related setup. Assign this task to a CPU. */
    /* 初始化子进程调度策略，优先级，调度类等进程调度相关成员 */
    retval = sched_fork(clone_flags, p);
    if (retval)
        goto bad_fork_cleanup_policy;

    retval = perf_event_init_task(p);
    if (retval)
        goto bad_fork_cleanup_policy;
    retval = audit_alloc(p);
    if (retval)
        goto bad_fork_cleanup_perf;
    /* copy all the process information */
    /* 子进程复制父进程信息，文件，信号，内存等 */
    shm_init_task(p);
    retval = security_task_alloc(p, clone_flags);
    if (retval)
        goto bad_fork_cleanup_audit;
    retval = copy_semundo(clone_flags, p);
    if (retval)
        goto bad_fork_cleanup_security;
    retval = copy_files(clone_flags, p);
    if (retval)
        goto bad_fork_cleanup_semundo;
    retval = copy_fs(clone_flags, p);
    if (retval)
        goto bad_fork_cleanup_files;
    retval = copy_sighand(clone_flags, p);
    if (retval)
        goto bad_fork_cleanup_fs;
    retval = copy_signal(clone_flags, p);
    if (retval)
        goto bad_fork_cleanup_sighand;
    retval = copy_mm(clone_flags, p); /* 复制mm_struct，如果设置CLONE_VM，则子进程task_struct->mm,task_struct->active_mm都等于父进程的task_struct->mm */
    if (retval)
        goto bad_fork_cleanup_signal;
    retval = copy_namespaces(clone_flags, p);
    if (retval)
        goto bad_fork_cleanup_mm;
    retval = copy_io(clone_flags, p);
    if (retval)
        goto bad_fork_cleanup_namespaces;
    /* 体系结构相关，复制task_struct->thread_struct内容，在此函数中子进程IP寄存器设置成ret_from_fork */
    retval = copy_thread_tls(clone_flags, args->stack, args->stack_size, p,
                 args->tls);
    if (retval)
        goto bad_fork_cleanup_io;

    stackleak_task_init(p);

    if (pid != &init_struct_pid) {
        pid = alloc_pid(p->nsproxy->pid_ns_for_children, args->set_tid,
                args->set_tid_size);
        if (IS_ERR(pid)) {
            retval = PTR_ERR(pid);
            goto bad_fork_cleanup_thread;
        }
    }

    /*
     * This has to happen after we've potentially unshared the file
     * descriptor table (so that the pidfd doesn't leak into the child
     * if the fd table isn't shared).
     */
    if (clone_flags & CLONE_PIDFD) {
        retval = get_unused_fd_flags(O_RDWR | O_CLOEXEC);
        if (retval < 0)
            goto bad_fork_free_pid;

        pidfd = retval;

        pidfile = anon_inode_getfile("[pidfd]", &pidfd_fops, pid,
                          O_RDWR | O_CLOEXEC);
        if (IS_ERR(pidfile)) {
            put_unused_fd(pidfd);
            retval = PTR_ERR(pidfile);
            goto bad_fork_free_pid;
        }
        get_pid(pid);    /* held by pidfile now */

        retval = put_user(pidfd, args->pidfd);
        if (retval)
            goto bad_fork_put_pidfd;
    }

#ifdef CONFIG_BLOCK
    p->plug = NULL;
#endif
    futex_init_task(p);

    /*
     * sigaltstack should be cleared when sharing the same VM
     */
    if ((clone_flags & (CLONE_VM|CLONE_VFORK)) == CLONE_VM)
        sas_ss_reset(p);

    /*
     * Syscall tracing and stepping should be turned off in the
     * child regardless of CLONE_PTRACE.
     */
    user_disable_single_step(p);
    clear_tsk_thread_flag(p, TIF_SYSCALL_TRACE);
#ifdef TIF_SYSCALL_EMU
    clear_tsk_thread_flag(p, TIF_SYSCALL_EMU);
#endif
    clear_tsk_latency_tracing(p);

    /* ok, now we should be set up.. */
    p->pid = pid_nr(pid);
    /* 子进程加入父进程线程组 */
    if (clone_flags & CLONE_THREAD) {
        p->exit_signal = -1;
        p->group_leader = current->group_leader;
        p->tgid = current->tgid;
    } else {
        if (clone_flags & CLONE_PARENT)
            p->exit_signal = current->group_leader->exit_signal;
        else
            p->exit_signal = args->exit_signal;
        p->group_leader = p;
        p->tgid = p->pid;
    }

    p->nr_dirtied = 0;
    p->nr_dirtied_pause = 128 >> (PAGE_SHIFT - 10);
    p->dirty_paused_when = 0;

    p->pdeath_signal = 0;
    INIT_LIST_HEAD(&p->thread_group);
    p->task_works = NULL;

    cgroup_threadgroup_change_begin(current);
    /*
     * Ensure that the cgroup subsystem policies allow the new process to be
     * forked. It should be noted the the new process's css_set can be changed
     * between here and cgroup_post_fork() if an organisation operation is in
     * progress.
     */
    retval = cgroup_can_fork(p);
    if (retval)
        goto bad_fork_cgroup_threadgroup_change_end;

    /*
     * From this point on we must avoid any synchronous user-space
     * communication until we take the tasklist-lock. In particular, we do
     * not want user-space to be able to predict the process start-time by
     * stalling fork(2) after we recorded the start_time but before it is
     * visible to the system.
     */

    p->start_time = ktime_get_ns();
    p->start_boottime = ktime_get_boottime_ns();

    /*
     * Make it visible to the rest of the system, but dont wake it up yet.
     * Need tasklist lock for parent etc handling!
     */
    write_lock_irq(&tasklist_lock);

    /* CLONE_PARENT re-uses the old parent */
    if (clone_flags & (CLONE_PARENT|CLONE_THREAD)) {
        p->real_parent = current->real_parent;
        p->parent_exec_id = current->parent_exec_id;
    } else {
        p->real_parent = current;
        p->parent_exec_id = current->self_exec_id;
    }

    klp_copy_process(p);

    spin_lock(&current->sighand->siglock);

    /*
     * Copy seccomp details explicitly here, in case they were changed
     * before holding sighand lock.
     */
    copy_seccomp(p);

    rseq_fork(p, clone_flags);

    /* Don't start children in a dying pid namespace */
    if (unlikely(!(ns_of_pid(pid)->pid_allocated & PIDNS_ADDING))) {
        retval = -ENOMEM;
        goto bad_fork_cancel_cgroup;
    }

    /* Let kill terminate clone/fork in the middle */
    if (fatal_signal_pending(current)) {
        retval = -EINTR;
        goto bad_fork_cancel_cgroup;
    }

    /* past the last point of failure */
    if (pidfile)
        fd_install(pidfd, pidfile);

    init_task_pid_links(p);
    if (likely(p->pid)) {
        ptrace_init_task(p, (clone_flags & CLONE_PTRACE) || trace);

        init_task_pid(p, PIDTYPE_PID, pid);
        if (thread_group_leader(p)) {
            init_task_pid(p, PIDTYPE_TGID, pid);
            init_task_pid(p, PIDTYPE_PGID, task_pgrp(current));
            init_task_pid(p, PIDTYPE_SID, task_session(current));

            if (is_child_reaper(pid)) {
                ns_of_pid(pid)->child_reaper = p;
                p->signal->flags |= SIGNAL_UNKILLABLE;
            }
            p->signal->shared_pending.signal = delayed.signal;
            p->signal->tty = tty_kref_get(current->signal->tty);
            /*
             * Inherit has_child_subreaper flag under the same
             * tasklist_lock with adding child to the process tree
             * for propagate_has_child_subreaper optimization.
             */
            p->signal->has_child_subreaper = p->real_parent->signal->has_child_subreaper ||
                             p->real_parent->signal->is_child_subreaper;
            list_add_tail(&p->sibling, &p->real_parent->children);
            list_add_tail_rcu(&p->tasks, &init_task.tasks);
            attach_pid(p, PIDTYPE_TGID);
            attach_pid(p, PIDTYPE_PGID);
            attach_pid(p, PIDTYPE_SID);
            __this_cpu_inc(process_counts);
        } else {
            current->signal->nr_threads++;
            atomic_inc(&current->signal->live);
            refcount_inc(&current->signal->sigcnt);
            task_join_group_stop(p);
            list_add_tail_rcu(&p->thread_group,
                      &p->group_leader->thread_group);
            list_add_tail_rcu(&p->thread_node,
                      &p->signal->thread_head);
        }
        attach_pid(p, PIDTYPE_PID);
        nr_threads++;
    }
    total_forks++; /* 创建进程数加1 */
    hlist_del_init(&delayed.node);
    spin_unlock(&current->sighand->siglock);
    syscall_tracepoint_update(p);
    write_unlock_irq(&tasklist_lock);

    proc_fork_connector(p);
    cgroup_post_fork(p);
    cgroup_threadgroup_change_end(current);
    perf_event_fork(p);

    trace_task_newtask(p, clone_flags);
    uprobe_copy_process(p, clone_flags);

    return p;

bad_fork_cancel_cgroup:
    spin_unlock(&current->sighand->siglock);
    write_unlock_irq(&tasklist_lock);
    cgroup_cancel_fork(p);
bad_fork_cgroup_threadgroup_change_end:
    cgroup_threadgroup_change_end(current);
bad_fork_put_pidfd:
    if (clone_flags & CLONE_PIDFD) {
        fput(pidfile);
        put_unused_fd(pidfd);
    }
bad_fork_free_pid:
    if (pid != &init_struct_pid)
        free_pid(pid);
bad_fork_cleanup_thread:
    exit_thread(p);
bad_fork_cleanup_io:
    if (p->io_context)
        exit_io_context(p);
bad_fork_cleanup_namespaces:
    exit_task_namespaces(p);
bad_fork_cleanup_mm:
    if (p->mm) {
        mm_clear_owner(p->mm, p);
        mmput(p->mm);
    }
bad_fork_cleanup_signal:
    if (!(clone_flags & CLONE_THREAD))
        free_signal_struct(p->signal);
bad_fork_cleanup_sighand:
    __cleanup_sighand(p->sighand);
bad_fork_cleanup_fs:
    exit_fs(p); /* blocking */
bad_fork_cleanup_files:
    exit_files(p); /* blocking */
bad_fork_cleanup_semundo:
    exit_sem(p);
bad_fork_cleanup_security:
    security_task_free(p);
bad_fork_cleanup_audit:
    audit_free(p);
bad_fork_cleanup_perf:
    perf_event_free_task(p);
bad_fork_cleanup_policy:
    lockdep_free_task(p);
#ifdef CONFIG_NUMA
    mpol_put(p->mempolicy);
bad_fork_cleanup_threadgroup_lock:
#endif
    delayacct_tsk_free(p);
bad_fork_cleanup_count:
    atomic_dec(&p->cred->user->processes);
    exit_creds(p);
bad_fork_free:
    p->state = TASK_DEAD;
    put_task_stack(p);
    delayed_free_task(p);
fork_out:
    spin_lock_irq(&current->sighand->siglock);
    hlist_del_init(&delayed.node);
    spin_unlock_irq(&current->sighand->siglock);
    return ERR_PTR(retval);
}
```

## 5、copy_mm()实现

copy_mm完成子进程对父进程内存空间的复制，Linux5.6.4中copy_mm()函数实现：
1、将新进程的mm（拥有的内存描述符表）和active_mm（正在使用的内存描述符表，所以内核线程的mm为空，active_mm为之前的用户进程的mm）置空；
2、如果当前进程current的mm（current->mm）为空，则直接返回。这个条件相对于判断是否是内核线程，如果为空，则说明是内核线程，这样新创建的内核线程的mm和active_mm就是NULL；
3、如果设置CLONE_VM标志，则子进程使用父进程的内存描述符mm和active_mm；
4、调用dup_mm创建子进程内存描述符并复制父进程内存描述符(current->mm)；内存描述符mm由mm_init()初始化，包括其成员mmap(进程VMA链表头)，mm_rb(VMA红黑树根)，mm_users（用户空间用户个数）和mm_count（内核引用该数据结构个数）引用计数设置为1。
5、设置子进程内存描述符mm和active_mm。

```
static int copy_mm(unsigned long clone_flags, struct task_struct *tsk)
{
    struct mm_struct *mm, *oldmm;
    int retval;

    tsk->min_flt = tsk->maj_flt = 0;
    tsk->nvcsw = tsk->nivcsw = 0;
#ifdef CONFIG_DETECT_HUNG_TASK
    tsk->last_switch_count = tsk->nvcsw + tsk->nivcsw;
    tsk->last_switch_time = 0;
#endif

    /* 将mm和active_mm置空 */
    tsk->mm = NULL;
    tsk->active_mm = NULL;

    /*
     * Are we cloning a kernel thread?
     *
     * We need to steal a active VM for that..
     */
    oldmm = current->mm;
    if (!oldmm)  /* 判断是否是内核线程 */
        return 0;

    /* initialize the new vmacache entries */
    vmacache_flush(tsk);

    /* 如果设置CLONE_VM标志，则子进程使用父进程的内存描述符 */
    if (clone_flags & CLONE_VM) {
        mmget(oldmm);
        mm = oldmm;
        goto good_mm;
    }

    retval = -ENOMEM;
    mm = dup_mm(tsk, current->mm);  /* 创建子进程内存描述符并复制父进程mm */
    if (!mm)
        goto fail_nomem;

  /* 设置子进程内存描述符 */
good_mm:
    tsk->mm = mm;
    tsk->active_mm = mm;
    return 0;

fail_nomem:
    return retval;
}
```

# 二、内核线程

内核线程只运行在内核态，因而内核线程的切换无需用户态和内核态的切换。与普通进程相比，内核线程有如下特点：
1、内核线程只运行在内核态，普通进程可以运行在内核态，也可以运行在用户态（通过系统调用陷入内核）。
2、内核线程只运行于内核态，只使用大于PAGE_OFFSET（3gb)的线性地址空间。普通进程可以使用4GB线性地址空间。（对32位系统而言）
3、内核线程可以直接调用schdule()让出CPU。
4、内核线程没有自己的内存描述符，因而进程描述符中的mm成员为NULL，而当内核线程运行时，其active_mm指向前一个运行进程的active_mm。

## 1、内核线程的创建

内核提供两个函数创建内核线程：
1、kernel_thread(int (*fn)(void *), void *arg, unsigned long flags)。入参分别为函数主体int (*fn)(void *)，函数传参void *arg，clone标志unsigned long flags。
2、kthread_create(threadfn, data, namefmt, arg…)宏定义。*参数分别为函数主体threadfn，函数传参data，内核线程名称namefmt。

## 2、kernel_thread()实现

kernel_thread是调用_do_fork()实现的。  
Linux5.6.4中kernel_thread的实现：

```
/*
 * Create a kernel thread.
 */
pid_t kernel_thread(int (*fn)(void *), void *arg, unsigned long flags)
{
    struct kernel_clone_args args = {
        .flags        = ((flags | CLONE_VM | CLONE_UNTRACED) & ~CSIGNAL),
        .exit_signal    = (flags & CSIGNAL),
        .stack        = (unsigned long)fn,
        .stack_size    = (unsigned long)arg,
    };

    return _do_fork(&args);
}
```

CLONE_VM标志避免复制调用进程的页表：内核线程不会访问用户地址空间，所以无需复制父进程页表。CLONE_UNTRACED标志保证不会有进程跟踪内核线程。

## 3、kthread_create()实现

```
/**
 * kthread_create - create a kthread on the current node
 * @threadfn: the function to run in the thread
 * @data: data pointer for @threadfn()
 * @namefmt: printf-style format string for the thread name
 * @arg...: arguments for @namefmt.
 *
 * This macro will create a kthread on the current node, leaving it in
 * the stopped state.  This is just a helper for kthread_create_on_node();
 * see the documentation there for more details.
 */
#define kthread_create(threadfn, data, namefmt, arg...) \
    kthread_create_on_node(threadfn, data, NUMA_NO_NODE, namefmt, ##arg)
```

kthread_create是一个宏定义，替换为kthread_create_on_node()。
kthread_create_on_node的函数注释告诉我们，kthread_create_on_node创建的进程是stop状态，需要wake_up_process()将其加入运行队列。

```
/**
 * kthread_create_on_node - create a kthread.
 * @threadfn: the function to run until signal_pending(current).
 * @data: data ptr for @threadfn.
 * @node: task and thread structures for the thread are allocated on this node
 * @namefmt: printf-style name for the thread.
 *
 * Description: This helper function creates and names a kernel
 * thread.  The thread will be stopped: use wake_up_process() to start
 * it.  See also kthread_run().  The new thread has SCHED_NORMAL policy and
 * is affine to all CPUs.
 *
 * If thread is going to be bound on a particular cpu, give its node
 * in @node, to get NUMA affinity for kthread stack, or else give NUMA_NO_NODE.
 * When woken, the thread will run @threadfn() with @data as its
 * argument. @threadfn() can either call do_exit() directly if it is a
 * standalone thread for which no one will call kthread_stop(), or
 * return when 'kthread_should_stop()' is true (which means
 * kthread_stop() has been called).  The return value should be zero
 * or a negative error number; it will be passed to kthread_stop().
 *
 * Returns a task_struct or ERR_PTR(-ENOMEM) or ERR_PTR(-EINTR).
 */
struct task_struct *kthread_create_on_node(int (*threadfn)(void *data),
                       void *data, int node,
                       const char namefmt[],
                       ...)
{
    struct task_struct *task;
    va_list args;

    va_start(args, namefmt);
    task = __kthread_create_on_node(threadfn, data, node, namefmt, args);
    va_end(args);

    return task;
}
```

kthread_create_on_node调用了__kthread_create_on_node实现内核线程创建。
__kthread_create_on_node创建了kthread_create_info变量，将创建内核线程的threadfn，data赋值到create，将create加入到kthread_create_list链表。

```
struct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),
                            void *data, int node,
                            const char namefmt[],
                            va_list args)
{
    DECLARE_COMPLETION_ONSTACK(done);
    struct task_struct *task;
    struct kthread_create_info *create = kmalloc(sizeof(*create),
                             GFP_KERNEL);

    if (!create)
        return ERR_PTR(-ENOMEM);
    create->threadfn = threadfn;
    create->data = data;
    create->node = node;
    create->done = &done;

    spin_lock(&kthread_create_lock);
    list_add_tail(&create->list, &kthread_create_list);
    spin_unlock(&kthread_create_lock);

    wake_up_process(kthreadd_task);
    /*
     * Wait for completion in killable state, for I might be chosen by
     * the OOM killer while kthreadd is trying to allocate memory for
     * new kernel thread.
     */
    if (unlikely(wait_for_completion_killable(&done))) {
        /*
         * If I was SIGKILLed before kthreadd (or new kernel thread)
         * calls complete(), leave the cleanup of this structure to
         * that thread.
         */
        if (xchg(&create->done, NULL))
            return ERR_PTR(-EINTR);
        /*
         * kthreadd (or new kernel thread) will call complete()
         * shortly.
         */
        wait_for_completion(&done);
    }
    task = create->result;
    if (!IS_ERR(task)) {
        static const struct sched_param param = { .sched_priority = 0 };
        char name[TASK_COMM_LEN];

        /*
         * task is already visible to other tasks, so updating
         * COMM must be protected.
         */
        vsnprintf(name, sizeof(name), namefmt, args);
        set_task_comm(task, name);
        /*
         * root may have changed our (kthreadd's) priority or CPU mask.
         * The kernel thread should not inherit these properties.
         */
        sched_setscheduler_nocheck(task, SCHED_NORMAL, &param);
        set_cpus_allowed_ptr(task, cpu_all_mask);
    }
    kfree(create);
    return task;
}
```

kthread_create_list是一个双向链表

```
#define LIST_HEAD_INIT(name) { &(name), &(name) }
#define LIST_HEAD(name) \
    struct list_head name = LIST_HEAD_INIT(name)
static LIST_HEAD(kthread_create_list);
```

真正使用kthread_create_list链表的是kthread。kthread是所有内核线程的父进程。kthread会遍历kthread_create_list链表，如果不为空，则获得kthread_create_list节点create(即__kthread_create_on_node中加入的create节点)，并将create从kthread_create_list链表中移除，调用create_kthread()创建内核线程，创建完成后继续遍历。当然kthread_create_list链表的添删由自旋锁kthread_create_lock保护。
create_kthread函数实现如下，从中可以看出饶了一圈最终还是调用kernel_thread()。

```
static void create_kthread(struct kthread_create_info *create)
{
    int pid;

#ifdef CONFIG_NUMA
    current->pref_node_fork = create->node;
#endif
    /* We want our own signal handler (we take no signals by default). */
    pid = kernel_thread(kthread, create, CLONE_FS | CLONE_FILES | SIGCHLD);
    if (pid < 0) {
        /* If user was SIGKILLed, I release the structure. */
        struct completion *done = xchg(&create->done, NULL);

        if (!done) {
            kfree(create);
            return;
        }
        create->result = ERR_PTR(pid);
        complete(done);
    }
}
```

## 4、0号进程——idle进程

0号进程是所有进程的祖先，Linux系统初始化阶段从无到有创建的一个内核线程。0号进程的进程描述符是静态分配的，也就是说idle进程是在start_kernel()里静态创建的，在早期内核版本任务描述符由INIT_TASK宏赋值，Linux5.6.4直接赋值。
关于进程描述符的介绍可以查看《深入Linux内核—进程描述》章节。

```
struct task_struct init_task
#ifdef CONFIG_ARCH_TASK_STRUCT_ON_STACK
    __init_task_data
#endif
= {
#ifdef CONFIG_THREAD_INFO_IN_TASK
    .thread_info    = INIT_THREAD_INFO(init_task),
    .stack_refcount    = REFCOUNT_INIT(1),
#endif
    .state        = 0,
    .stack        = init_stack,
    .usage        = REFCOUNT_INIT(2),
    .flags        = PF_KTHREAD,
    .prio        = MAX_PRIO - 20,
    .static_prio    = MAX_PRIO - 20,
    .normal_prio    = MAX_PRIO - 20,
    .policy        = SCHED_NORMAL,
    .cpus_ptr    = &init_task.cpus_mask,
    .cpus_mask    = CPU_MASK_ALL,
    .nr_cpus_allowed= NR_CPUS,
    .mm        = NULL,
    .active_mm    = &init_mm,
    .restart_block    = {
        .fn = do_no_restart_syscall,
    },
    .se        = {
        .group_node     = LIST_HEAD_INIT(init_task.se.group_node),
    },
    .rt        = {
        .run_list    = LIST_HEAD_INIT(init_task.rt.run_list),
        .time_slice    = RR_TIMESLICE,
    },
    .tasks        = LIST_HEAD_INIT(init_task.tasks),
#ifdef CONFIG_SMP
    .pushable_tasks    = PLIST_NODE_INIT(init_task.pushable_tasks, MAX_PRIO),
#endif
#ifdef CONFIG_CGROUP_SCHED
    .sched_task_group = &root_task_group,
#endif
    .ptraced    = LIST_HEAD_INIT(init_task.ptraced),
    .ptrace_entry    = LIST_HEAD_INIT(init_task.ptrace_entry),
    .real_parent    = &init_task,
    .parent        = &init_task,
    .children    = LIST_HEAD_INIT(init_task.children),
    .sibling    = LIST_HEAD_INIT(init_task.sibling),
    .group_leader    = &init_task,
    RCU_POINTER_INITIALIZER(real_cred, &init_cred),
    RCU_POINTER_INITIALIZER(cred, &init_cred),
    .comm        = INIT_TASK_COMM,
    .thread        = INIT_THREAD,
    .fs        = &init_fs,
    .files        = &init_files,
    .signal        = &init_signals,
    .sighand    = &init_sighand,
    .nsproxy    = &init_nsproxy,
    .pending    = {
        .list = LIST_HEAD_INIT(init_task.pending.list),
        .signal = {{0}}
    },
    .blocked    = {{0}},
    .alloc_lock    = __SPIN_LOCK_UNLOCKED(init_task.alloc_lock),
    .journal_info    = NULL,
    INIT_CPU_TIMERS(init_task)
    .pi_lock    = __RAW_SPIN_LOCK_UNLOCKED(init_task.pi_lock),
    .timer_slack_ns = 50000, /* 50 usec default slack */
    .thread_pid    = &init_struct_pid,
    .thread_group    = LIST_HEAD_INIT(init_task.thread_group),
    .thread_node    = LIST_HEAD_INIT(init_signals.thread_head),
#ifdef CONFIG_AUDIT
    .loginuid    = INVALID_UID,
    .sessionid    = AUDIT_SID_UNSET,
#endif
#ifdef CONFIG_PERF_EVENTS
    .perf_event_mutex = __MUTEX_INITIALIZER(init_task.perf_event_mutex),
    .perf_event_list = LIST_HEAD_INIT(init_task.perf_event_list),
#endif
#ifdef CONFIG_PREEMPT_RCU
    .rcu_read_lock_nesting = 0,
    .rcu_read_unlock_special.s = 0,
    .rcu_node_entry = LIST_HEAD_INIT(init_task.rcu_node_entry),
    .rcu_blocked_node = NULL,
#endif
#ifdef CONFIG_TASKS_RCU
    .rcu_tasks_holdout = false,
    .rcu_tasks_holdout_list = LIST_HEAD_INIT(init_task.rcu_tasks_holdout_list),
    .rcu_tasks_idle_cpu = -1,
#endif
#ifdef CONFIG_CPUSETS
    .mems_allowed_seq = SEQCNT_ZERO(init_task.mems_allowed_seq),
#endif
#ifdef CONFIG_RT_MUTEXES
    .pi_waiters    = RB_ROOT_CACHED,
    .pi_top_task    = NULL,
#endif
    INIT_PREV_CPUTIME(init_task)
#ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN
    .vtime.seqcount    = SEQCNT_ZERO(init_task.vtime_seqcount),
    .vtime.starttime = 0,
    .vtime.state    = VTIME_SYS,
#endif
#ifdef CONFIG_NUMA_BALANCING
    .numa_preferred_nid = NUMA_NO_NODE,
    .numa_group    = NULL,
    .numa_faults    = NULL,
#endif
#ifdef CONFIG_KASAN
    .kasan_depth    = 1,
#endif
#ifdef CONFIG_TRACE_IRQFLAGS
    .softirqs_enabled = 1,
#endif
#ifdef CONFIG_LOCKDEP
    .lockdep_depth = 0, /* no locks held yet */
    .curr_chain_key = INITIAL_CHAIN_KEY,
    .lockdep_recursion = 0,
#endif
#ifdef CONFIG_FUNCTION_GRAPH_TRACER
    .ret_stack    = NULL,
#endif
#if defined(CONFIG_TRACING) && defined(CONFIG_PREEMPTION)
    .trace_recursion = 0,
#endif
#ifdef CONFIG_LIVEPATCH
    .patch_state    = KLP_UNDEFINED,
#endif
#ifdef CONFIG_SECURITY
    .security    = NULL,
#endif
}
```

对于SMP架构，CPU每个core都会有idle进程，这些idle进程都是复制bootcore的idle进程。在start_kernel中调用rest_init启动kernel_init内核线程，会调用smp_init，最终由idle_threads_init遍历CPU core完成idle进程复制。内核会定义每CPU变量为每个core创建一个全局变量记录idle进程的进程描述符。

```
/* idle进程每CPU变量 */
static DEFINE_PER_CPU(struct task_struct *, idle_threads);
void __init idle_threads_init(void)
{
    unsigned int cpu, boot_cpu;

    boot_cpu = smp_processor_id();

    for_each_possible_cpu(cpu) { /* 遍历CPU */
        if (cpu != boot_cpu)
            idle_init(cpu); /* 调用fork_idle复制boot_cpu的idle进程 */
    }
}
```

## 5、1号进程-init进程

1号进程init进程是个用户态进程，是所有用户态进程的祖先。
init进程是start_kernel()函数最后调用rest_init创建的。
进程0创建了init进程，创建完成后进程0执行cpu_idle。init进程被创建后执行kernel_init函数，kernel_init最终调用execve(/sbin/init)启动用户态init进程。

```
noinline void __ref rest_init(void)
{
    struct task_struct *tsk;
    int pid;

    rcu_scheduler_starting();
    /*
     * We need to spawn init first so that it obtains pid 1, however
     * the init task will end up wanting to create kthreads, which, if
     * we schedule it before we create kthreadd, will OOPS.
     */
    /* 创建init进程 */
    pid = kernel_thread(kernel_init, NULL, CLONE_FS);
    /*
     * Pin init on the boot CPU. Task migration is not properly working
     * until sched_init_smp() has been run. It will set the allowed
     * CPUs for init to the non isolated CPUs.
     */
    rcu_read_lock();
    tsk = find_task_by_pid_ns(pid, &init_pid_ns);
    set_cpus_allowed_ptr(tsk, cpumask_of(smp_processor_id()));
    rcu_read_unlock();

    numa_default_policy();
    /* 创建kthreadd进程 */
    pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);
    rcu_read_lock();
    kthreadd_task = find_task_by_pid_ns(pid, &init_pid_ns);
    rcu_read_unlock();

    /*
     * Enable might_sleep() and smp_processor_id() checks.
     * They cannot be enabled earlier because with CONFIG_PREEMPTION=y
     * kernel_thread() would trigger might_sleep() splats. With
     * CONFIG_PREEMPT_VOLUNTARY=y the init task might have scheduled
     * already, but it's stuck on the kthreadd_done completion.
     */
    system_state = SYSTEM_SCHEDULING;

    complete(&kthreadd_done);

    /*
     * The boot idle thread must execute schedule()
     * at least once to get things moving:
     */
    schedule_preempt_disabled();
    /* Call into cpu_idle with preempt disabled */
    /* idle进程执行cpu_idle */
    cpu_startup_entry(CPUHP_ONLINE);
}
```

## 6、2号进程-kthread进程

2号进程kthread进程是个内核线程，是所有内核线程的父进程。
同样，kthread内核线程也是start_kernel()函数最后调用rest_init创建的。
创建kthread内核线程后执行kthread()函数。kthread()函数的主要任务就是创建内核线程。
Linux5.6.4中kthreadd的实现：
1、设置task_struct.comm为“kthreadd”，即设置内核线程名称为kthreadd；
2、设置kthreadd信号sa_handler为SIG_IGN，即对所有信号的action为IGNORE；
3、设置kthreadd亲和所有CPU；
4、kthread遍历kthread_create_list链表寻找可创建的内核线程，如kthread_create()实现一节介绍，kthread_create完成对kthread_create_list链表节点的添加。
5、kthread会遍历kthread_create_list链表，如果为空，则设置任务状态为TASK_INTERRUPTIBLE，并继续判断链表是否为空；
6、如果不为空，则设置任务状态为TASK_RUNNING，则设置则获得kthread_create_list节点create(即__kthread_create_on_node中加入的create节点)，并将create从kthread_create_list链表中移除，调用create_kthread()创建内核线程，创建完成后继续遍历。
由于kthread最终调用do_fork完成内核线程的创建，因此kthread是所有内核线程的父进程。

```
int kthreadd(void *unused)
{
    struct task_struct *tsk = current;

    /* Setup a clean context for our children to inherit. */
    /* 设置任务名为“kthreadd” */
    set_task_comm(tsk, "kthreadd");
    /* 设置信号action为IGNORE */
    ignore_signals(tsk);
    /* 设置任务亲和所有CPU */
    set_cpus_allowed_ptr(tsk, cpu_all_mask);
    set_mems_allowed(node_states[N_MEMORY]);

    current->flags |= PF_NOFREEZE;
    cgroup_init_kthreadd();

    for (;;) {
        set_current_state(TASK_INTERRUPTIBLE);
        if (list_empty(&kthread_create_list))
            schedule();
        __set_current_state(TASK_RUNNING);

        spin_lock(&kthread_create_lock);
        while (!list_empty(&kthread_create_list)) {
            struct kthread_create_info *create;

            create = list_entry(kthread_create_list.next,
                        struct kthread_create_info, list);
            /*将create从kthread_create_list链表中摘除*/
            list_del_init(&create->list);
            spin_unlock(&kthread_create_lock);

            /*调用create_kthread创建内核线程*/
            create_kthread(create);

            spin_lock(&kthread_create_lock);
        }
        spin_unlock(&kthread_create_lock);
    }

    return 0;
}
```

## 7、其他内核线程

除了上述内核线程外，Linux还创建了很多内核线程用于其他事务。例如：  
**ksoftirqd**  
软中断任务，运行tasklet。关于软中断可以参看《深入Linux内核—中断和异常》。  
**kswapd**  
内存回收内核线程。关于内存可以参看《深入Linux内核-内存管理》。

# 三、进程退出

进程终止了它们执行的代码，必须通知内核以便内核释放进程所占用的资源，包括内存，文件及其他资源。  
进程终止的一般方法是调用exit()。另外，C编译程序总是把exit()插入main函数的最后一条语句之后。

## 1、进程终止的系统调用

exitgroup()系统调用，终止线程组。对应内核函数do_group_exit()。C语言的库函数exit使用系统调用exit_group来终止整个线程组。
exit()系统调用，终止某个线程。对应内核函数do_exit()。Linux线程库函数pthread_exit使用系统调用exit来终止某一个线程。

## 2、do_group_exit()实现

do_group_exit函数会杀死属于current线程组的所有进程。它接受进程终止代号作为参数，进程终止代号可能是系统调用exit_group（正常结束）指定的一个值，也可能是内核提供的一个错误码（异常结束）。
1、检查退出进程的SIGNAL_GROUP_EXIT标志是否不为0，如果不为0，说明内核已经开始为线程组执行退出过程，将current->signal->group_exit_code作为退出码。
2、调用zap_other_threads杀死current线程组中其他进程。函数扫描current->thread_group链表，向不同于current进程发送SIGKILL信号，所有接收到信号的进程都将执行do_exit()函数。
3、调用do_exit()函数，将进程终止代号传入，结束current。

```
/*
 * Nuke all other threads in the group.
 */
int zap_other_threads(struct task_struct *p)
{
    struct task_struct *t = p;
    int count = 0;

    p->signal->group_stop_count = 0;

    /* 遍历线程组内所有线程，除current */
    while_each_thread(p, t) {
        task_clear_jobctl_pending(t, JOBCTL_PENDING_MASK);
        count++;

        /* Don't bother with already dead threads */
        if (t->exit_state)
            continue;
        /* 向线程发送SIGKILL信号 */
        sigaddset(&t->pending.signal, SIGKILL);
        signal_wake_up(t, 1);
    }

    return count;
}

/*
 * Take down every thread in the group.  This is called by fatal signals
 * as well as by sys_exit_group (below).
 */
void
do_group_exit(int exit_code)
{
    struct signal_struct *sig = current->signal;

    BUG_ON(exit_code & 0x80); /* core dumps don't get here */

    /* 检查退出进程的SIGNAL_GROUP_EXIT标志是否不为0，如果不为0，说明内核已经开始为线程组执行退出过程，将current->signal->group_exit_code作为退出码。 */
    if (signal_group_exit(sig))
        exit_code = sig->group_exit_code;
    else if (!thread_group_empty(current)) {
        struct sighand_struct *const sighand = current->sighand;

        spin_lock_irq(&sighand->siglock);
        if (signal_group_exit(sig))
            /* Another thread got here before we took the lock.  */
            exit_code = sig->group_exit_code;
        else {
            sig->group_exit_code = exit_code;
            sig->flags = SIGNAL_GROUP_EXIT;
            zap_other_threads(current);
        }
        spin_unlock_irq(&sighand->siglock);
    }

    do_exit(exit_code);
    /* NOTREACHED */
}
```

## 3、do_exit()实现

所有进程的终止都是由do_exit()完成的。do_exit()的入参是进程终止代号。  
1、获取进程描述符tsk = current;  
2、调用profile_task_exit通知；  
3、如果在中断上下文或者终止进程0，则产生Kernel panic；

```
void __noreturn do_exit(long code)
{
    struct task_struct *tsk = current;
    int group_dead;

    profile_task_exit(tsk);
    kcov_task_exit(tsk);

    WARN_ON(blk_needs_flush_plug(tsk));

    /* 如果在中断上下文，则产生Kernel panic */
    if (unlikely(in_interrupt()))
        panic("Aiee, killing interrupt handler!");
    /* 如果终止进程0，则产生Kernel panic */
    if (unlikely(!tsk->pid))
        panic("Attempted to kill the idle task!");

    /*
     * If do_exit is called because this processes oopsed, it's possible
     * that get_fs() was left as KERNEL_DS, so reset it to USER_DS before
     * continuing. Amongst other possible reasons, this is to prevent
     * mm_release()->clear_child_tid() from writing to a user-controlled
     * kernel address.
     */
    set_fs(USER_DS);

    ptrace_event(PTRACE_EVENT_EXIT, code);

    validate_creds_for_do_exit(tsk);

    /*
     * We're taking recursive faults here in do_exit. Safest is to just
     * leave this task alone and wait for reboot.
     */
    if (unlikely(tsk->flags & PF_EXITING)) {
        pr_alert("Fixing recursive fault but reboot is needed!\n");
        futex_exit_recursive(tsk);
        set_current_state(TASK_UNINTERRUPTIBLE);
        schedule();
    }

    /* 设置进程flag标志PF_EXITING */
    exit_signals(tsk);  /* sets PF_EXITING */

    if (unlikely(in_atomic())) {
        pr_info("note: %s[%d] exited with preempt_count %d\n",
            current->comm, task_pid_nr(current),
            preempt_count());
        preempt_count_set(PREEMPT_ENABLED);
    }

    /* sync mm's RSS info before statistics gathering */
    if (tsk->mm)
        sync_mm_rss(tsk->mm);
    acct_update_integrals(tsk);
    group_dead = atomic_dec_and_test(&tsk->signal->live);
    if (group_dead) {
        /*
         * If the last thread of global init has exited, panic
         * immediately to get a useable coredump.
         */
        if (unlikely(is_global_init(tsk)))
            panic("Attempted to kill init! exitcode=0x%08x\n",
                tsk->signal->group_exit_code ?: (int)code);

#ifdef CONFIG_POSIX_TIMERS
        hrtimer_cancel(&tsk->signal->real_timer);
        exit_itimers(tsk->signal);
#endif
        if (tsk->mm)
            setmax_mm_hiwater_rss(&tsk->signal->maxrss, tsk->mm);
    }
    acct_collect(code, group_dead);
    if (group_dead)
        tty_audit_exit();
    audit_free(tsk);

    tsk->exit_code = code;
    taskstats_exit(tsk, group_dead);

    /* 进程描述符分离页表，如果没有其他进程使用这些页表，则释放 */
    exit_mm();

    if (group_dead)
        acct_process();
    trace_sched_process_exit(tsk);

    /* 进程描述符分离信号量，文件系统，打开的文件描述符，命名空间等，如果没有其他进程共享这些数据结构，则释放 */
    exit_sem(tsk);
    exit_shm(tsk);
    exit_files(tsk);
    exit_fs(tsk);
    if (group_dead)
        disassociate_ctty(1);
    exit_task_namespaces(tsk);
    exit_task_work(tsk);
    exit_thread(tsk);
    exit_umh(tsk);

    /*
     * Flush inherited counters to the parent - before the parent
     * gets woken up by child-exit notifications.
     *
     * because of cgroup mode, must be called before cgroup_exit()
     */
    perf_event_exit_task(tsk);

    sched_autogroup_exit_task(tsk);
    cgroup_exit(tsk);

    /*
     * FIXME: do that only when needed, using sched_exit tracepoint
     */
    flush_ptrace_hw_breakpoint(tsk);

    exit_tasks_rcu_start();
    exit_notify(tsk, group_dead);
    proc_exit_connector(tsk);
    mpol_put_task_policy(tsk);
#ifdef CONFIG_FUTEX
    if (unlikely(current->pi_state_cache))
        kfree(current->pi_state_cache);
#endif
    /*
     * Make sure we are holding no locks:
     */
    debug_check_no_locks_held();

    if (tsk->io_context)
        exit_io_context(tsk);

    if (tsk->splice_pipe)
        free_pipe_info(tsk->splice_pipe);

    if (tsk->task_frag.page)
        put_page(tsk->task_frag.page);

    validate_creds_for_do_exit(tsk);

    check_stack_usage();
    preempt_disable();
    if (tsk->nr_dirtied)
        __this_cpu_add(dirty_throttle_leaks, tsk->nr_dirtied);
    exit_rcu();
    exit_tasks_rcu_finish();

    lockdep_free_task(tsk);
    do_task_dead();
}
```

# 四、总结

用户进程，线程创建由clone()、fork()和vfork()系统调用完成。
内核线程创建由kthread_create完成。
用户进程，线程和内核线程最终都是调用do_fork实现。
do_fork核心是子进程复制父进程的资源，这些资源复制的选择由clone_flag控制。
用户进程的祖先是init进程（1号进程），由start_kernel启动。
内核线程的父进程都是kthread。
进程退出由exit_group()和exit()系统调用完成，最终都是调用do_exit()实现。
